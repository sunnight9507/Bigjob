{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 가치의 재발견\n",
    "\n",
    "#### Data Value\n",
    "- Edyn / Nest & Google / Remember / Netatmo / Data & Company's Value / IoT on Wikipedia / HYPE Cycle of Gartner / Data Technology / Beyond Big Data\n",
    "\n",
    "## 2. 빅데이터와 4차 산업혁명\n",
    "\n",
    "- Productivity / RAMI 4.0 / 3 Factors for Production / Mass Prodction / Smart Factory / Data, Software & Machine / Data Based Decision / \n",
    "\n",
    "## 3. 빅데이터의 이해\n",
    "\n",
    "#### 1) 빅데이터 정의\n",
    "- 대량의 **데이터 분석**을 통해, 일반적으로는 볼 수 없었던 **새로운 사실, 패턴, 법칙을 발견**하여 **새로운 비즈니스 가치를 창출**하는 기법\n",
    "\n",
    "\n",
    "#### 2) 빅데이터 분석 진행 과정\n",
    "- 1) Descriptive Analysis(Hindsight)\n",
    "    - 조직별 정형 데이터를 취합/분석하여 리포팅\n",
    "- 2) Diagnostic Analysis(Insight)\n",
    "    - 전사차원의 정형데이터를 Mining과 통계기법으로 분석하여 리포팅하고 Business 의사결정에 활용\n",
    "- 3) Predictive Analysis(Foresight)\n",
    "    - 사내외 모든 데이터를 활용하고 Advanced Analysis를 이용하여 예측/최적화 모델을 제시함으로써 Business 의사 결정을 지원\n",
    "        \n",
    "#### 3) 3V\n",
    "- **다양한(Variety)** 형태의 **대용량(Volume)** 데이터를 **빠르게(Velocity)** 실시간으로 분석\n",
    "    - **가치(Value)**를 창출 \n",
    "    - 3V 기반의 **Insight와 Foresight**를 통한 **가치창출**\n",
    "    \n",
    "#### 4) 저장 기술\n",
    "- **나눠서 많이 저장**하고, **동시에 빠르게 처리**하는 솔루션\n",
    "    - 기존 데이터베이스 대비 \"비용은 1/10으로 속도는 10시간이 10초로\"\n",
    "- 과거 방식 : 기존의 DB보다 큰 DB로 교체\n",
    "- 현재 방식 : **필요한만큼 연결해 대용량화**(저가 저장장치 확장)\n",
    "\n",
    "#### 5) 분석 도구\n",
    "- 분석전용도구\n",
    "    - SAS / SPSS / R\n",
    "- 분석 언어\n",
    "    - R / python / Scala\n",
    "- Self Service Analytics\n",
    "    - rapidminer / KNIME\n",
    "    \n",
    "#### 6) 비정형 분석\n",
    "\n",
    "- Text 등의 방대한 비정형 데이터를 빠른 속도(Near Real Time)로 분석\n",
    "\n",
    "#### 7) Data Cleaning\n",
    "\n",
    "- **1) RawData 저장**\n",
    "    - **MPP 기반의 대용량 분산 저장소** ex) Hadoop(Cloudera, Map-R 등)\n",
    "    - **In-memory Cache, Key-Value Store, Column지향 DB등 다양한 Data 저장 및 처리 기술 지원**\n",
    "- **2) Data Cleaning**\n",
    "    - **RawData 추출, 정형데이터로 변환, 정형저장소 적재 활동을 수행하는 단계**\n",
    "        - ex) ETL, ETT\n",
    "- **3) 정형데이터 저장**\n",
    "    - **정형데이터를 Table 형태로 저장하는 단계**\n",
    "        - RDBMS, NoSQL(Hbase), Hive, Hadoop 등\n",
    "- **4) 분석 저장소 저장**\n",
    "    - **Data Scientist가 분석활동을 수행하기 요구되는 데이터를 저장하는 단계**\n",
    "        - SandBox : 분석을 위한 임시저장 공간\n",
    "- **5) EDW 저장**\n",
    "    - **Enterprise Data Warehouse 구성을 위해 저장하는 단계**\n",
    "        - 분석을 위한 Source Data로써, 또는 모델가종 및 기간 시스템을 위한 기업의 정보 인프라\n",
    "        \n",
    "## 4. Data Scientist와 Citizen Data Scientist\n",
    "\n",
    "#### Data Scientist\n",
    "- [Data Scientist 커리큘럼](http://www.hakawati.co.kr/174)\n",
    "- [필요 역량](https://oralytics.com/2012/06/13/data-science-is-multidisciplinary/)\n",
    "    - Business Skills\n",
    "    - Data Science\n",
    "    - IT Skills\n",
    "    \n",
    "#### Citizen Data Scientist\n",
    "\n",
    "- Self Serviece Analytics\n",
    "- Data Scientist보다 분석, IT역량은 많이 필요하지 않음\n",
    "\n",
    "## 5. 빅데이터 분석 방법론\n",
    "\n",
    "#### 1) 방법론(Methology)\n",
    "\n",
    "- 개개인의 역량과 경험에 의존하지 않고 누가 수행하던 \"일정수준의 질과 양\"이 보장될 수 있는 체계\n",
    "\n",
    "#### 2) 방법론 순환 사이클\n",
    "\n",
    "- 암묵적인 지식(문서화) -> 형식지(지식화) -> 형식적인 지식(내면화) -> 암묵지(공유화) ->\n",
    "\n",
    "#### 3) KDD\n",
    "\n",
    "- 1) Selection : 분석을 위한 Data Set을 편성하거나 Sampling 또는 필요한 변수를 선택하는 과정\n",
    "- 2) Pre processing : 일관성 있는 데이터 분석을 위하여 데이터를 정재하거나 선처리하는 과정\n",
    "- 3) Transformation : 데이터의 차원 축소하거나 파생 데이터 생성하여 분석용 Data Set 생성\n",
    "- 4) Data mining : 다양한 분석기법을 사용해 데이터의 패턴을 찾고 모델링화\n",
    "- 5) Interpretation / Evalutaion : 분석된 데이터 패턴 및 모델을 해석하거나 평가\n",
    "\n",
    "#### 4) SEMMA\n",
    "\n",
    "- 1) Sample : 분석 Data 생성(통계적 추출, 조건 추출) / 모델링 및 모델 평가를 위한 Data 준비\n",
    "- 2) Exploration : 분석 Data 탐색\n",
    "- 3) Modification : 분석 Data 수정/변환\n",
    "- 4) Modeling : 모델 구축 / Data의 숨겨진 Pattern 발견\n",
    "- 5) Assessment : 모델 평가 및 검증\n",
    "\n",
    "#### 5) CRISP-DM\n",
    "\n",
    "- 1) Business understanding : 비즈니스의 목적과 데이터 마이닝의 목표를 수립하고 프로젝트 계획을 수립\n",
    "    - 업무 목적 파악 / 상황 파악 / 데이터 마이닝 목표 설정 / 프로젝트 계획 수립\n",
    "- 2) Data understanding : 분석에 필요한 Initial Data를 분석하고 품질을 검토하여 분석용 데이터 확보를 위한 준비단계\n",
    "    - 초기 데이터 수집 / 데이터 기술 분석 / 데이터 탐색 / 데이터 품질 확인\n",
    "- 3) Data preparation : 데이터를 획득하여 선별, 통합, 정재과정을 통해 분석용 Dataset을 편성\n",
    "    - 분석용 데이터셋 선택 / 데이터 정제 / 분석용 데이터셋 편성 / 데이터 통합 / 데이터 Format\n",
    "- 4) Modeling : 다양한 분석 기법을 활용하여 모델링을 하고 설계된 테스트 계획에 따라 평가\n",
    "    - 모델링 기법 선택 / 모델 테스트 게획 설계 / 모델 작성 / 모델 평가\n",
    "- 5) Evaluation : 분석결과를 평가하고 과정을 Review\n",
    "    - 분석결과 평가 / 모델링 과정 평가 / 모델 적용성 평가 \n",
    "- 6) Deployment : 전개 및 모니터링 계획을 수립하고 과제 종료\n",
    "    - 전개 계획 수립 / 모니터링과 유지보수 계획 수립 / 프로젝트 종료 보고서 작성 / 프로젝트 리뷰\n",
    "\n",
    "####  7) Ref' Model\n",
    "\n",
    "- Planning / Data preparing / Data analyzing / System developing / Deploying\n",
    "\n",
    "#### 8) KDD & SEMMA & CRISP-DM 차이\n",
    "\n",
    "- ![KDD & SEMMA & CRISP-DM 차이](../img/1.png)\n",
    "\n",
    "## 6. 분석기획 및 데이터 수집 단계\n",
    "\n",
    "#### 1) Planning\n",
    "\n",
    "- 비즈니스 도메인 이해\n",
    "- 프로젝트 목적 정의\n",
    "- Data 이해\n",
    "\n",
    "#### 2) 단기 vs 장기 분석 기획\n",
    "\n",
    "- 당면한 분석 주제의 해결(과제 단위) / 지속적 분석 문화 내재화(마스터 플랜 단위)\n",
    "- 1차 목표 : Speed & Test / Accuracy & Deploy\n",
    "- 과제의 유형 : Quick-WIn / Long Term View\n",
    "- 접근 방식 : 문제 해결 / 문제 발굴\n",
    "\n",
    "#### 3) 하향식 접근 방법\n",
    "\n",
    "- Problem Discovery : 비즈니스 모델기반 내부 문제 탐색, 사례 기반 외부 문제 탐색\n",
    "- Problem Definition : 데이터 분석 문제 변환\n",
    "- Solution Search : 수행 방안 도출\n",
    "- Feasibility Study : 타당성 평가 => 과제 선정\n",
    "\n",
    "#### 4) Data Preparing\n",
    "\n",
    "- 통상적으로 가장 오래 걸리는 부분\n",
    "- Data 정의 및 탐색\n",
    "\n",
    "#### 5) EDA의 이해\n",
    "\n",
    "- Resistance / Residual / Re-expression / Visualization\n",
    "\n",
    "#### 6) 데이터 거버넌스\n",
    "\n",
    "- 전사 차원의 모든 데이터에 대한 정책, 지침, 표준화, 전략을 수립하고, 데이터를 관리하는 조직과 프로세스를 구축함으로써 고품질의 데이터를 활용하여 기업의 가치 창출을 지원하는 체계\n",
    "- 주요 내용\n",
    "    - Data 품질관리\n",
    "        - 데이터 품질 / 데이터 표준화\n",
    "    - Data 구조관리\n",
    "        - Master 데이터 관리 / 데이터 분산 및 통합 / Meta 데이터 관리\n",
    "    - Data 관리체계 수립\n",
    "        - 데이터 변경관리 / 데이터 관리조직 / 데이터 보안\n",
    "        \n",
    "## 7. 데이터 분석 단계\n",
    "\n",
    "#### 1) Data analyzing\n",
    "\n",
    "- Desciptive : observe(what happened)\n",
    "- Diagnostic : explain(why did it happen)\n",
    "- Predictive : anticipate(what will happen)\n",
    "- Prescriptive : act(operationalize)\n",
    "\n",
    "#### 2) 분석 과정\n",
    "\n",
    "- 1) Prepare Dataset\n",
    "- 2) Text Analysis\n",
    "- 3) EDA\n",
    "- 4) Modeling\n",
    "- 5) Model Assess\n",
    "- 6) Model Deployment\n",
    "\n",
    "## 8. 시스템화 및 전개 단계\n",
    "\n",
    "#### 1) System developing\n",
    "\n",
    "- Model 이해\n",
    "- Designing system\n",
    "- Developing system\n",
    "- Testing\n",
    "\n",
    "#### 2) Deploying\n",
    "\n",
    "- 유지 보수 계획\n",
    "- 프로젝트 전체 평가\n",
    "\n",
    "## 9. 빅데이터 프로젝트의 CSF\n",
    "\n",
    "#### 1) Data Governance\n",
    "\n",
    "- MDM / Policies / Processes / Risk management / Regulatory Compliance / Data Quality / Technology / Organization\n",
    "\n",
    "## 10. R 설치 및 기초 프로그램"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
